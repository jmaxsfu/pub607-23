# PUB 607 Fundamentals

## On File Management

A file is a **metaphor** for a structured bundle of data in a computer. Files do not actually exist in your computer, or on its hard drive (which is not in fact hard). It's a metaphor that shapes a set of behaviours around how we deal with files.XXXXXXXX The metaphor is closely related to the idea of "documents," but not exactly equivalent.

The file idea, more or less, dates to the late 1960s, early 1970s, and was popularized through the spread of the Unix operating system (which is still with us). We still think largely in terms of filesXXXXXXXX, although alternative metaphors (or patterns) are becoming more common: streams; queries; things pulled together on the fly out of databases.XXXXXXXX

Files are typically organized in **Filesystems**; the one we all take for granted is the "hierarchical file system," where there is a hierarchical set of "folders" that uniquely locate and organize files. It seems natural because it's been with us for decades, but it's not natural, and it does NOT have to be this way.

Inside a file is data... typically, the "header" of the file is a bundle of data that identifies the file type and provides some basic metadata so that your operating system (and you) can make sense of it. Following thatXXXXXXXX is a bundle of data that represents the "content" of the file: a text, an image, a sound, your taxes, a set of database relations, or whatever.

For the most part, files are DUMB. They can't *do* anything; they sit there passively until operated on by an **application**, which can open, read, edit, manipulate, and/or save the file.

There are as many **file types** as there are pieces of software, more or less. Which is to say, gazillions of them. File standards are the exceptions, not the rule, and so every different version of a word processor has its own file types. The result is files that end upXXXXXXXX being unusable, or at least only partially usable, if they aren't open by the exact application that they were designed for.

There are, notably, a handful of important standards, where file types work across a number of different applications and aren't bound to a single app:

**Text files**, made up only of lines of text characters. This was the old standard for Unix files, and these are, handily, mostly human-readable. Sometimes text files have a specific internal format: e.g., .csv spreadsheets.

**Image, sound, and video files** that we pass around on the Internet (JPGs, PNGs, MP3s, MOVs, etc.). Since the early Internet was pluralistic enough to demand **open file formats** that a variety of different tools and applications could all use. These are structured bundles of, for the most part, *sampled* data about images, sounds, etc. More about this below...

**XML files**, which are text files with specific structures expressed in them. XML files are theoretically openable and usable by any XML-aware application. In reality it's not quite so simple.

**Defacto common standards** like .docx files or .pdf files are *sort-of* open and *sort of* interoperable, but they are still largely controlled by Microsoft and Adobe. They have achieved standards-like status because they are ubiquitous.

## So many files! How can I manage?

XXXXXXXX

**File naming** is, for the most part, unregulated. There is a common practice wherein we use a particular 3- or 4-letter code at the end of the filename to indicade the file type (e.g. ".txt" or ".pdf"). But it's not a formal standard; it's just how most people and a fair bit of software recognizes things.

What you put before the **dot** in a file name is up to you. The trouble with this practice, obviously, is that your computer (and your inbox) eventually fills up with `untitled.docx` files or `final.xlsx`, or worse: `FINALfinal.pdf`.

It's pretty common for people to use short, easily typed filenames and then rely on the enclosing folder name for context. This, of course, falls apart as soon as you take the file out of that folder and send it to someone.

Regular computer filesystems, for the most part, do not track the history of changes to files. If I have two files named `final.docx`, I might have a clue about which one is final-er than the other by comparing the date in the file metadata; but that date might only reflect when the file was *sent to me* rather than when it was actually edited. 

There *are* systems for **tracking changes** -- or **versions** -- in files and filesystems, and they are definitely worth using. Generally, this means going to the trouble of doing so, though.

A good old DIY workaround for this is to embed version information directly in the filename, like `final-JMax-Dec13.docx` -- It's hardly foolproof, but it might be better than nothing.

at best, we have folk rpactices XXXXXXXX

## Content Management concepts and software

Part of what's so successful about the "file" metaphor is that it allows us to think of digital things *as if they were paper documents*. One implication of this practice is that we don't tend to think of a file as existing in more than once place at once. We also don't really think of them as dynamic. If a file changes, we like to think of it as a new version of that file, as opposed to the same file.XXXXXXXX

**Content management systems** (CMS) break some of these conceptual limitations. Instead of files living in hierarchies of folders -- on my computer, on your computer, in your inbox, or in my inbox -- a CMS keeps a file in one central online place, and anyone who needs to see it, work on it, etc. comes to it, rather than a copy of the file travelling to them. Therefore multiple people can all be accessing the same file at once. That necessitates keeping track of changes to the file -- if you and I are both editing it, what happens, and when?

There are lots of different kinds of content management systems. **Wordpress** is one kind. **Dropbox** is another kind. **Github** is another. Each makes slightly different trade-offs between the kind of flexibility it offers, against how far it breaks the paper-document metaphor. 

**Wordpress** very much keeps a single, centralized copy of a document (for instance, a post), but it makes the change history of that document easy to see and manage. **Dropbox** also keeps a change history, but it mostly hides it away, so your file in Dropbox looks and acts a lot more like a regular old file on your own computer. **Github** has both local files -- in your own folder hierarchy -- and centrally managed files, tracking the change history across all of these (and across multiple users), and keeping all the different versions in sync; it's harder to get your head around initially, but it is super powerful and flexible as a result.

XXXXXXXX


# A History of Digitized Text

What's so special about text?

It *matters* what kind of stuff is in the file. A binary file (like an image, or audio, or an InDesign document) is, fundamentally hard to edit. It needs to be reconstituted by some application into a workable format -- for instance, in an audio editing application -- then saved back into the file format.

Text files -- and text-based data -- on the other hand, are editable as they are, because their structure corresponds exactly (or at least closely) to what they represent. A plain text file is made up exactly of the letters you read when you read it. Editing the file is identical with editing the text.

XXXXXXXX word

Text is special. This goes beyond the mechanics of files and file formats. Text is special because it's uniquely editable, changeable, mutable. What's that? You thought it was special because it was unchanging! But that's *print*, not *text*. The "text" comes into being at the point when Gutenberg makes the type "moveable."

Text can be edited; it can be parsed; it can be processed in ways that are incredibly broadly understood, literally by every literate person. Compare that to all that's required to edit two seconds out of a video file -- or crop your sister's ex from a family photo. XXXXXXXX

(Actually, when we have systems that *generate* audio or video, we typically interact with it via 'notation,' which is intended to work sort of like text. Think about music scores, for instance. And XML, more about which below...)

Text is special because we know how to process it, and so making computers process text is an extension of our own understanding, as opposed to something unique that has to be invented (like Photoshop or something).

## A Tale of Two Paradigms
 
 XXXXXXXX

Interestingly, the history of how we think about text in computers has two parallel traditions, very different in approach. These intersect here and there, but are almost two distinct *paradigms*.

The first tradition starts with text files, and builds structure into these files in order to deal with things like formatting, metadata, and so on. This tradition comes out of old-school typesetting and leads through Standard Generalized Markup Language (SGML, from the 1980s), HyperText Markup Language (HTML, early 1990s), to eXtensible Markup Language (XML, from the late 1990s). It is the approach that underlies the Web and most "digital publishing" formats.

In this way of thinking, the text and its innate structures are of paramount importance, and things like formatting and layout are secondary; they need to be layered onto the underlying text structures. This approach is extremely well suited to accessibility, as a single text can be manifest in different formats for different audiences or different contexts.

The second tradition, largely invented at Xerox PARC in the 1970s, makes page layout primary, and everything else is secondary. This tradition begins with "Desktop Publishing" (DTP) leading through word processors and software like PageMaker, QuarkXpress, and InDesign, and reaches its full express inXXXXXXXX the PDF -- which is a perfect virtual image of a page. The goal is "WYSIWYG" -- *what you see is what you get* -- that what you see on the computer screen is what you'll get on the printed page. This tradition has been dominant in publishing since around 1990, and it utterly replaced traditional typesetting. 



But the page-first paradigm presents all sorts of difficulties for multiple formats, and especially for accessibility, since the underlying text needs to be extracted from what the software is XXXXXXXX adapted to: page layout. 

In 2023, we live in a world where these two traditions co-exist, but only interact with some difficulty (as seen with the "born-accessible ebook"). There are ways of moving between the two approaches;


being aware that there ARE two distinct approaches is the first step to that. You would be surprised how few people on this planet really understand this.


## The Elusive Goal of Interoperability 

The goal of **interoperability** -- or, to put it conversely: avoiding **lock-in** or forced dependence on a particular vendor or platform -- has been approached in a couple of different keysXXXXXXXX. Foremost is the idea of an open, explicitly described file format, as opposed to a file format whose internal structure is only known or fully understood to the vendor. 

Word's .doc and .docx formats, for instance, are well enough known for file translators to exist (you can import Word files into InDesign, for instance), but the file format suits Microsoft's business interests above all. The insides of an .indd file are almost completely opaque.

Text files are an excellent choice for open file formats, because text files are, at least theoretically, readably by human beings. As a result, lots of open formats are at their base levels text files. More sophisticated structures are built up within them using standardized conventions.

XXXXXXXX


