# Digital Text Production

## Alphabets, ASCII, and Unicode

"In the beginning was the *Word*"

- ...but it's all just ones and zeros, right?

A 'Word' = a Byte. 8 bits. 

How do we make bytes into something useful, like text? It's just a convention. A general agreement that this particular number -- represented as a byte, which, in 8-bits, is a number between 0 and 255, between 0 and 1111111, or (more conveniently, in hex) between 0 and FF -- stands for a particular letter of the alphabet.

XXXXXXXX
Capital 'A' is ASCII code 65 -- or 41 in hex (right?) -- 'B' is 66, and so on.

ASCII -- the "American Standard Code for Information Interchange" was an enormously successful standard -- still with us today, after 60 years (1963). 


![A chart showing the letters corresponding to the ASCII codes 0 through 127. The first 31 codes are control codes, originally from historic telegraph and teletype systems. Codes 65 through 90 are the letters of the uppercase alphabet; 97 through 122 are the lowercase alphabet.](img/ASCII-Table.png "ASCII Chart")



How many letters in the English alphabet? 26  
x2 for upper and lowercase - 52  
+ ten digits - 62  
+ 30 punctuation marks - 92  
+ 30-odd control codes for early systems - 127  
+ the last binary bit reserved for error control - 255  

So ASCII is an alphabet with 127 possible characters. Sounds great, what could possibly go wrong?

To get around the anglocentrism of that, a variety NON-standard schemes emerged. "Eight-bit extended character sets." Apple had one, Microsoft had a different one. IBM had another. Various standards were proposed (e.g., ISO 8859) but not uniformly adopted.

But a mess, generally. And non-Europeans (e.g. China) were still utterly left out.


## Unicode

A solution came forward circa 1997, in the Unicode standard, which could encode a possible 1,112,064 possible characters

The simplest Unicode implementation, UTF-8, made for an easy replacement for ASCII. Based on fixed 8-bit chunks (up to 4, for a million characters), and "a UTF-8 file that contains only ASCII characters is identical to an ASCII file."

But implementations are still complex. This is literally like changing the alphabet from under us.

![A graph showing the relative usage of three standards, ASCII, ISO 8859, and Unicode UTF-8, from 2000 to 2010; At around 2008, Unicode begins to overtake ASCII and the older ISO standard](img/UnicodeGrow2b.png "Unicode Growth, 2000–2010")

XXXXXXXX

Unicode is supported by pretty much everything now. Mac OS X, Windows, Unix and Unix-derived operating systems. XML, HTML, and the Web and Internet standards.

BUT LEGACY SYSTEMS ARE STILL WITH US.. old software (esp critical databases) sometimes don't, and so stuff messes up.

If you see little rectangles, or these things -- � ￼ ⸻ -- something in your toolchain has failed to support your Unicode.

Unicode support means is that you can type accented characters, and curly quotes, and em-dashes, and greek, and whatever WITHOUT WORRYING about it. Until recently, this was not so simple.

You used to have to write  U+2014 or `&#x2014;` or `&mdash;` but with Unicode, you can just type an em-dash. On the Mac, shift-option-hyphen.

And, of course, you can also write in Arabic or Bengali, or whatever.


Important piece of trivia about Unicode:

A "code-point" is not a **glyph**. A code-point is an abstract representation of a character in the system. A glyph is an actual mark. So, individual glyphs -- for instance, **ligatures** -- are variable, and are actually defined in individual fonts. 

In all the fonts in the world, there are only a tiny handful that represent all of the Unicode space.

Pay attention to what Unicode support your typefaces include. Old fonts are sometimes terrible.

Interlude on Indigenous typography.XXXXXXXX

## Line breaks

Once we have an alphabet we can all (!) agree on, we can put text in files.

The original, most basic structural element in text files is the **line break**. Also known as "carriage return". Unfortunately, in ASCII (and Unicode), there are two of them: line feed (LF, from teletype) and carriage return (CR, from typewriters) are represented. And if there are two ways to do things, people will do both. Or either. And so, historically, some systems used LF, some CR, and some, unfortunately (Microsoft we are looking at you), BOTH. 

It's not a huge hassle, but something to be aware of.

XXXXXXXX

The old Unix standard for text files had line breaks (LF) making lines about 80 characters long. Early text editor software edited one line at a time. So the line was the fundamental unit of structure in a text file.

Later, after decent display technology came along, and the "word wrap" feature became normal, people stopped breaking lines at the 80-character mark, and instead let lines go as long as they need to be. So today, in a text file, an entire paragraph would be one "line" even though, when you look at it on screen, it's wrapped into several visual lines.

## Understanding Markup

Beyond line breaks, any attempts to put more structure into text files requires the use of some kind of special **delimiter** to make it possible to distinguish between regular content and information ABOUT the content. 

"Markup" is a very old idea. As far back as the 15th century, for instance, the copy that was handed to a typesetter or compositor would be the "fair copy" of the text plus some extra markings that indicated formatting: make the title centred on the page; set this part in a bigger face; indent this part; and so on. The standard set of "copyeditor's marks" are derived from this tradition.

When computers began to be used in typesetting in the 1960s and 1970s, a whole host of systems were invented to embed typesetting instructions (for a machine to read) in the text to be set. There are a LOT of different ways of doing this -- often using punctuation in weird ways. 

Embedding typesetting instructions directly into an article or book chapter is a dodgy thing to do. First, if the instructions get mixed up with the text itself, you have a mess. Second, instructions to a typesetting machine are complicated and ugly.

In the 1970s, there was a trend toward using "generic markup" -- in which the embedded typesetting instruction wasn't raw code, but rather a label, like "title" or "indented-quote" or something like that. A bit of processing software would then read the file and translate those generic labels to the raw typesetting code. One advantage here is that copy marked up for one typesetting machine could be switched to another kind of machine by changing the processor, as opposed to having to re-do the text itself. 

The outcome of this thinking, in the late 1970s and early 1980s, was called Generalized Markup Language (GML), which was then certified as an ISO standard in 1986: Standard Generalized Markup Language (**SGML**).

In SGML:

1. XXXXXXXX Markup is kept in plain text files;

2. Markup tags are delimited by < and > characters;

3. Markup tags identify the semantic structures of the text, not formatting instructions; formatting is handled separately;

4. The 'vocabulary' of possible tags is domain-specific. You can make up a markup language for any context or situation;

5. Markup tags (almost) always come in pairs, surrounding the text that is being identified; 

6. Markup tags thus form a nested hierarchy of structures in the text; a text is thus a tree-shaped structure; or an "ordered hierarchy of content objects";

7. This hierarchy is readable by a piece of software called a *parser*; furthermore, rules specifying which tags can be used, and in which order and combinations. These rules can be checked by a piece of software called a *validating parser.* (one of the key designers of SGML was a lawyer)

Between 1986 and the late 1990s, the primary users of SGML were the American defense department contractors -- the makers of planes and bombs and tanks and things. This is because the Pentagon make SGML a documentation requirement for all contractors -- for the same of interoperability and longevity (avoiding lock-in).

The goal of **interoperability** -- or, to put it conversely: avoiding **lock-in** or forced dependence on a particular vendor or platform -- has been approached in a couple of different keysXXXXXXXX. Foremost is the idea of an open, explicitly described file format, as opposed to a file format whose internal structure is only known or fully understood to the vendor. 

Word's .doc and .docx formats, for instance, are well enough known for file translators to exist (you can import Word files into InDesign, for instance), but the file format suits Microsoft's business interests above all. The insides of an .indd file are almost completely opaque.

Text files are an excellent choice for open file formats, because text files are, at least theoretically, readably by human beings. As a result, lots of open formats are at their base levels text files. More sophisticated structures are built up within them using standardized conventions.

\





In 1990, though, Tim Berners-Lee used SGML to create the markup language for his World-Wide Web project. **HTML** (HyperText Markup Language) defines web pages, and allows them to be interlinked. Within a year or two, the number of people using HTML outnumbered the defence contractors using other kinds of SGML.

XXXXXXXX

Right from the beginning, **accessibility** was a goal of SGML and XML (see, for instance, <https://www.w3.org/2000/10/DIAWorkshop/accesssep.html>). Because the markup defines the semantic structures of the text only, and keeps formatting processes separate and secondary, it is possible to have a single XML document that produces typeset print, braille, and mobile-phone versions -- by specifying different processing for the same source text.

In 1997, a committee drew up a design for a "version 2.0" of SGML, written with the Internet in mind. It was a bit simpler, more streamlined, and did away with the need for *validation* (there weren't any lawyers on the committee). They might have called it SGML 2.0, but instead they thought it would sound better if they called it **XML**, because X is the sexiest of all letters, right?


In practice, XML defines only how the tags are written; it doesn't specify what the tags are. That part can be "domain-specific," which means that there are many XML languages, each of which is designed to do a particular kind of work.

See [some examples of XML](XMLexamples.md)

26:40  + 10 for examples


## But What About Formatting

XML only tells us is what is *in* the text -- the content and its structures and parts -- but we can use those structures as hooks for formatting rules.

A **stylesheet** defines formatting rules for named structures in the text. Conceptually, this works the same in Microsoft Word, in Adobe InDesign, in your web page, and in XML more generally. 

We define rules that say things like: body copy should be 10pt Garamond on 14pt line spacing, with a 56 em line length. First-level heads should be 18pt Gill Sans -- unless they appear in the context of a sidebar, in which case it should be 12pt instead. 

A stylesheet like this produces a "templated" design -- as opposed to being hand-crafted or bespoke. The power of a templated design is that the same stylesheet can be applied to many documents. It also means that one stylesheet can be swapped for another -- changing the formatting of a document without changing the text itself. Such an approach may be useful in the context of accessibility, or in multi-mode delivery.

This formal separation of the text (and its named structures) and the formatting rules is one example of the concept of "separation of concerns," which is a more general design pattern. We have had separation of concerns in publishing since Gutenberg put moveable type into practice, and the abstract idea of a text -- in the form of a **marked up** manuscript that compositors would use in typesetting -- came to drive formatting. 

This separation of the *platonic* ideal of the text from any particular printed instance of it has both delighted and vexed scholars and critics ever since. At this very point, when the text becomes *abstract and mutable*, it also becomes capable of *fixity and durability* over centuries owing to its production and distribution in mass quantities.

Ironically, the Desktop Publishing tradition, embodied today in InDesign, runs completely counter to this idea... in InDesign, format *is* structure, not the other way around.MORE XXXXXX



## HTML, CSS

Though it has taken a tortured path over the past thirty years, the HTML that makes up the Web has been the dominant stream of XML development. Purists and pedants will argue that HTML isn't *really* XML. But they are purists and pedants. It is too.

One problem was that for the first whole decade of the Web, there was no separate formatting system in place, and so all the formatting in the early web was done by hacking the HTML itself in terrible ways.

One commonplace was to achieve layouts by padding layouts with "invisible pixels" -- a 1-pixel by 1-pixel .gif file that was inserted and then stretched (in the HTML) to whatever dimensions were required for the layout. Another horrible idea was the use of tables with invisible borders to achieve layouts. And ubiquitous was typographic specifications written right into the HTML.

This eventually got solved with Cascading Style Sheets (CSS), which web browsers began to support around the turn of the century. CSS gave designers a separate system to define layout, typography, and even some interactivity, leaving the HTML to do what it was designed to do: define the structural components of the text. 

What really made this system work was the rise of blogging and other content-management systems (e.g., Wordpress), where publication-level details like layout, typography, and "themes" were kept in the back end, and authors were encouraged to concern themselves with the text alone. After Wordpress, HTML on the web got cleaner and more standardized, making it more like what XML was supposed to be.

Today, lots and lots of systems beyond websites are built using HTML. EBook standards -- both the consortium-backed EPUB format and most (but not all) Amazon Kindle file formats have HTML inside, representing the content itself. Loads of technical documentation systems, online help systems, and so on all use HTML as a basic system. There is a significant trend to building scholarly journals in HTML, as opposed to a more complex and specialized XML tagset. Even a few trade publishers -- Hachette in particular -- have HTML at the core of their book production workflows.

HTML has emerged as a general-purpose prose markup language. There are other MLs for specific industrial and scientific applications, but probably 90% of the time, HTML is sufficient.

## Markdown

The trouble with HTML is that it's ugly and probably unnecessarily verbose. Looking at it raw, one would never want to write or edit in HTML directly. It always will require some kind of editing tool to provide a friendly interface. Some of those interfaces will even pretend to be "WYSIWYG" even though this is an oxymoron in the context of markup.

One particularly interesting alternative was developed in the 2004 by blogging pioneers John Gruber and Aaron Swartz. Markdown was a way of writing on plain text files with an *extremely minimalist* set of extra formatting cues added -- that could then be automatically converted to HTML. They called it markdown -- it'a joke -- and released it online.

You're looking at it.

Markdown, while visually minimal, is explicit and complete enough to be *unambiguously* transformed into HTML by a simple software routine. That means that markdown is an alternative form of markup that *does that same work* as HTML, but it doesn't look like HTML or XML at all.

Markdown caught on in the years since 2004, and became embedded in lots of different web publishing systems. A host of software tools were developed to support it, and to allow writing, editing, previewing, converting, and so on. 

For most intents and purposes, markdown can be used anywhere that HTML is needed, because it's trivially easy to convert between the two. Markdown removes the need for a pseudo-WYSIWYG editing interface. But *much more importantly* it keeps close to the key advantage of text files in the first place: you are looking at the content, and the file, and they are the same thing; there's no extra interpretation going on, in between you and the file itself. There is no mystery. We might call this "WYSIATITIAM": What you see is all there is; there isn't any more." Maybe, in honour of Madeline, "TATITIAM"

## Pandoc

One of the key pieces of software we will use with markdown is Pandoc -- the "universal document converter."  <https://pandoc.org>

Pandoc is a simple, open-source tool that can take any structured content (or even semi-structured, with caveats), parse it, and re-create it in any other structured format. It was originally designed as a markdown-to-HTML conversion tool, but it has been generalized to work with dozens of different input and output formats. 

What that means is that it takes any structured (or even semi-structured) document format, and parses it into an internal representation. That internal representation can then be re-written in any other structured document format.

Pandoc is extremely high-quality software, and it is *exquisitely* well documented. I have often said that "a close reading of the Pandoc user manual would constitute a whole course in document production." Since you're currently taking a course in ebook production, it would be a good idea to at least familiarize yourself with Pandoc's incredibly well-written User's Manual: <https://pandoc.org/MANUAL.html>

Pandoc, it must be said, has a command-line interface. That means you use it by typing commands into a command shell, like it was 1983 all over again. You have one of these, though: on your Mac, it's called "Terminal." On Windows, it's called "Powershell."

I know, it's old, and it makes you feel like you're in an 80s movie. But the command-line interface actually really works incredibly well, especially for text processing, because it was invented for text processing. If you want to be one of the cool kids, you'll play with the preferences in your shell so that it's green type on a black background. Embrace your inner geek! 


Here's a [Command-shell cheat sheet](Commands.md)

Pandoc isn't hard to use, once you get the general idea of how it works. Here's a [Pandoc Tutorial](Pandoc.md) 

43:00 + 10 for examples
