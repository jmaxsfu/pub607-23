Audio and Textio

I have been thinking about the difference between text -- a synthetic generative medium in which meaning is built up from just 26 letters -- and continuous media like audio -- where meaning unfolds strictly in time.

These two modes, which between them comprise a good deal of what we think of as storytelling, are so completely different kinds of media. What I mean by that is how we work with them: how we produce them, how we edit them, how we manage and distribute them, and how we receive and consume them. 

Text is not time-based. It may require time to get through, but time is a function of the work of encoding or decoding, which may be faster or slower due to a variety of factors. At heart, though, the writing and the reading experience are largely time-independent. Maryanne Wolf, in Proust and the Squid, talks about the speed of the brain-based processes that make up reading, and how, once you've successfully learned to read, these processes are pretty much automatic and happen at blindingly fast speeds -- leaving your conscious attention to mind things like meaning and association and reflection. None of this is tied to the unfolding of time in any experientially meaningful sense.

Audio, though, is completely about time. What we hear -- and what we listen to -- is a flow of sound; the sequence, and the continuity of the sequence, is key to the experience. We can speed up or slow down playback, as we can speed up or slow down out speech, but we can only do so within pretty close limits (2x or so). Further, discontinuity in sound -- where things are interrupted, or there is a bad edit, mess with our appreciation and our ability to understand what is going on. Our experience of sound demands continutity of flow.

Text, in being a system of atomistic bits and pieces, is infinitely malleable: we can take text apart and put it together again easily, so long as we obey the laws that govern understandability: spelling, syntax, grammar, and so on. These meaning-making rules, though, don't have much at all to do with how text itself works -- which is how the same alphabet can serve for almost any human language, plus thousands of nonhuman ones too (by which I mean math, logic, code, and so forth), all which may have different rules for meaningful composition.

Audio, in being a continuous stream, has to be handled in a more holistic way. It is much closer to the time-based stream of experience itself. And while technology allows us to cut, copy, and paste audio -- and to digitally process in myriad ways -- the scariest thing to do is to break its continuity. An uttered sentence must be allowed to unfurl in its entirety; a musical phrase needs to come to completion; even ambient background noise is glaringly obvious if it is interrupted or spliced together.

Digital media, of course, reduces both text and audio to a sequence of bits; essentially making it like alphabetic text (which is all composed of patterns from 26 possible letters) but an order of magnitude more concise: digital has only two possible representational states: on or off; 1 or 0. The pattern of the sequence then becomes the important part. Note that this is doing what the alphabet already does, but much more simply. The result is that text editing and processing become much easier in digital media, but not necessarily of a different quality. Audio and continuous media, though, become -- potentially at least -- something completely different, capable of being synthesized (using a synthesizer, duh), capable of being processed in ways that are theoretically unimaginable before the advent of digital. And yet, in practice, most of the time, what we do with the digital production and editing of audio is to work with continuous streams: effectively, to mimic what we've always done with audio, be it live performance or analogue recordings. The vast majority of digital effects in use for audio production are imitations of analogue processing.

Counter-examples to my categorization are instructive. Audio experiences that feature and foreground cut-up or synthetically assembled sound -- examples include hip-hop DJing, early 20th-century cubist new music, and loads and loads of electronica -- are notable in how they buck the traditional trends. It is also interesting to note that where these forms are actually popular, they cleave to fairly straightforward traditions of rhythm: consider hip hop vs those old cubist compositions, for instance. 

What about text that is thought of as continuous flow? Examples would be the modernist stream-of-consciousness styles (from Virginia Woolf to Jack Kerouac); interestingly, within that tradition we find William S Burrough's "cut-up" composition technique, which brings us full circle.

But text may not have seemed as synthetic as it does today -- for technological reasons. Tim Ingold, in his odd little book, *Lines: A Brief History* (Routledge 2007), makes a firm distinction between the kind of writing we do with a pen in our hands -- indeed, tracing a line on the paper -- and that which we do with a keyboard. The tradition of writing with a keyboard draws not only on the digital representation of text in computers, but also on moveable type, where Gutenberg's great advances made text into reassembleable bits rather than a continuous flow of ink. The difference is subtle, and maybe even artifical, but it's interesting to think of our historical positioning.

